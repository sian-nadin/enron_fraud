{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Persons of Interest in the Enron Fraud\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "This project will be used to build a person of interest identifier (POI) based on financial and email data made public as a result of the Enron scandal. To assist with this I will be using a hand-generated list of persons of interest in the fraud case, which includes individuals who were indicted, reached a settlement or plea deal with the government, or testified in exchange for prosecution immunity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Enron email and financial data have been combined into a dictionary, where each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. The features in the data fall into three major types, namely financial features, email features and POI labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"/tools/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    enron_data = pickle.load(data_file)\n",
    "df = pd.DataFrame.from_dict(enron_data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data set\n",
    "We'll start off by briefly explore the data set to find out what type of values we're dealing with, if there's a lot of missing values etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955</td>\n",
       "      <td>2902</td>\n",
       "      <td>2869717</td>\n",
       "      <td>4484442</td>\n",
       "      <td>1729541</td>\n",
       "      <td>4175000</td>\n",
       "      <td>126027</td>\n",
       "      <td>1407</td>\n",
       "      <td>-126027</td>\n",
       "      <td>1729541</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>304805</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>182466</td>\n",
       "      <td>257817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>477</td>\n",
       "      <td>566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916197</td>\n",
       "      <td>4046157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1757552</td>\n",
       "      <td>465</td>\n",
       "      <td>-560222</td>\n",
       "      <td>5243487</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>864523</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>5634343</td>\n",
       "      <td>6680544</td>\n",
       "      <td>1200000</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10623258</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>239671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260455</td>\n",
       "      <td>827696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000</td>\n",
       "      <td>145796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82782</td>\n",
       "      <td>63014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-201641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    salary to_messages deferral_payments total_payments  \\\n",
       "ALLEN PHILLIP K     201955        2902           2869717        4484442   \n",
       "BADUM JAMES P          NaN         NaN            178980         182466   \n",
       "BANNANTINE JAMES M     477         566               NaN         916197   \n",
       "BAXTER JOHN C       267102         NaN           1295738        5634343   \n",
       "BAY FRANKLIN R      239671         NaN            260455         827696   \n",
       "\n",
       "                   exercised_stock_options    bonus restricted_stock  \\\n",
       "ALLEN PHILLIP K                    1729541  4175000           126027   \n",
       "BADUM JAMES P                       257817      NaN              NaN   \n",
       "BANNANTINE JAMES M                 4046157      NaN          1757552   \n",
       "BAXTER JOHN C                      6680544  1200000          3942714   \n",
       "BAY FRANKLIN R                         NaN   400000           145796   \n",
       "\n",
       "                   shared_receipt_with_poi restricted_stock_deferred  \\\n",
       "ALLEN PHILLIP K                       1407                   -126027   \n",
       "BADUM JAMES P                          NaN                       NaN   \n",
       "BANNANTINE JAMES M                     465                   -560222   \n",
       "BAXTER JOHN C                          NaN                       NaN   \n",
       "BAY FRANKLIN R                         NaN                    -82782   \n",
       "\n",
       "                   total_stock_value           ...           loan_advances  \\\n",
       "ALLEN PHILLIP K              1729541           ...                     NaN   \n",
       "BADUM JAMES P                 257817           ...                     NaN   \n",
       "BANNANTINE JAMES M           5243487           ...                     NaN   \n",
       "BAXTER JOHN C               10623258           ...                     NaN   \n",
       "BAY FRANKLIN R                 63014           ...                     NaN   \n",
       "\n",
       "                   from_messages    other from_this_person_to_poi    poi  \\\n",
       "ALLEN PHILLIP K             2195      152                      65  False   \n",
       "BADUM JAMES P                NaN      NaN                     NaN  False   \n",
       "BANNANTINE JAMES M            29   864523                       0  False   \n",
       "BAXTER JOHN C                NaN  2660303                     NaN  False   \n",
       "BAY FRANKLIN R               NaN       69                     NaN  False   \n",
       "\n",
       "                   director_fees deferred_income long_term_incentive  \\\n",
       "ALLEN PHILLIP K              NaN        -3081055              304805   \n",
       "BADUM JAMES P                NaN             NaN                 NaN   \n",
       "BANNANTINE JAMES M           NaN           -5104                 NaN   \n",
       "BAXTER JOHN C                NaN        -1386055             1586055   \n",
       "BAY FRANKLIN R               NaN         -201641                 NaN   \n",
       "\n",
       "                                 email_address from_poi_to_this_person  \n",
       "ALLEN PHILLIP K        phillip.allen@enron.com                      47  \n",
       "BADUM JAMES P                              NaN                     NaN  \n",
       "BANNANTINE JAMES M  james.bannantine@enron.com                      39  \n",
       "BAXTER JOHN C                              NaN                     NaN  \n",
       "BAY FRANKLIN R             frank.bay@enron.com                     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 21\n",
      "Total number of people: 146\n",
      "Number of POIs in data set: 18\n",
      "Number of POI in poi_names.txt: 35\n"
     ]
    }
   ],
   "source": [
    "print 'Number of features:', len(df.columns)\n",
    "print 'Total number of people:', df['poi'].count()\n",
    "print 'Number of POIs in data set:', df.loc[df.poi == True, 'poi'].count()\n",
    "\n",
    "count = 0\n",
    "with open('poi_names.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if '(y)' in line or '(n)' in line:\n",
    "            count += 1\n",
    "print \"Number of POI in poi_names.txt:\", count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of quantified salaries is: 95\n",
      "The total number of given email addresses is: 111\n",
      "The number of NaN payments is: 21\n"
     ]
    }
   ],
   "source": [
    "# How many people in this dataset have a quantified salary, known email address or NaN payments?\n",
    "\n",
    "print \"The number of quantified salaries is:\", (df['salary'] !='NaN').sum()\n",
    "print \"The total number of given email addresses is:\", (df['email_address'] !='NaN').sum()\n",
    "print \"The number of NaN payments is:\", (df['total_payments'] =='NaN').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN's found in the financial data could be interpreted as 0. Looking at the insider pay document we can see that some employees have 0 listed for their bonus. Therefore I will replace the NaNs in the financial data with 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n",
    "df = df.replace('NaN', np.nan)\n",
    "df[financial_features] = df[financial_features].fillna(0)"
   ]
  },
  {
<<<<<<< HEAD
||||||| merged common ancestors
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in NaN for email features as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_features = ['to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "df[email_features] = df[email_features].fillna(df[email_features].median())"
   ]
  },
  {
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also neeed to fill in NaN for email features as well. I will fill in the missing values with the median of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_features = ['to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "df[email_features] = df[email_features].fillna(df[email_features].median())"
   ]
  },
  {
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>477.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>239671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      salary  to_messages  deferral_payments  total_payments  \\\n",
       "ALLEN PHILLIP K     201955.0       2902.0          2869717.0       4484442.0   \n",
       "BADUM JAMES P            0.0          NaN           178980.0        182466.0   \n",
       "BANNANTINE JAMES M     477.0        566.0                0.0        916197.0   \n",
       "BAXTER JOHN C       267102.0          NaN          1295738.0       5634343.0   \n",
       "BAY FRANKLIN R      239671.0          NaN           260455.0        827696.0   \n",
       "\n",
       "                    exercised_stock_options      bonus  restricted_stock  \\\n",
       "ALLEN PHILLIP K                   1729541.0  4175000.0          126027.0   \n",
       "BADUM JAMES P                      257817.0        0.0               0.0   \n",
       "BANNANTINE JAMES M                4046157.0        0.0         1757552.0   \n",
       "BAXTER JOHN C                     6680544.0  1200000.0         3942714.0   \n",
       "BAY FRANKLIN R                          0.0   400000.0          145796.0   \n",
       "\n",
       "                    shared_receipt_with_poi  restricted_stock_deferred  \\\n",
       "ALLEN PHILLIP K                      1407.0                  -126027.0   \n",
       "BADUM JAMES P                           NaN                        0.0   \n",
       "BANNANTINE JAMES M                    465.0                  -560222.0   \n",
       "BAXTER JOHN C                           NaN                        0.0   \n",
       "BAY FRANKLIN R                          NaN                   -82782.0   \n",
       "\n",
       "                    total_stock_value           ...            loan_advances  \\\n",
       "ALLEN PHILLIP K             1729541.0           ...                      0.0   \n",
       "BADUM JAMES P                257817.0           ...                      0.0   \n",
       "BANNANTINE JAMES M          5243487.0           ...                      0.0   \n",
       "BAXTER JOHN C              10623258.0           ...                      0.0   \n",
       "BAY FRANKLIN R                63014.0           ...                      0.0   \n",
       "\n",
       "                    from_messages      other  from_this_person_to_poi    poi  \\\n",
       "ALLEN PHILLIP K            2195.0      152.0                     65.0  False   \n",
       "BADUM JAMES P                 NaN        0.0                      NaN  False   \n",
       "BANNANTINE JAMES M           29.0   864523.0                      0.0  False   \n",
       "BAXTER JOHN C                 NaN  2660303.0                      NaN  False   \n",
       "BAY FRANKLIN R                NaN       69.0                      NaN  False   \n",
       "\n",
       "                   director_fees  deferred_income  long_term_incentive  \\\n",
       "ALLEN PHILLIP K              0.0       -3081055.0             304805.0   \n",
       "BADUM JAMES P                0.0              0.0                  0.0   \n",
       "BANNANTINE JAMES M           0.0          -5104.0                  0.0   \n",
       "BAXTER JOHN C                0.0       -1386055.0            1586055.0   \n",
       "BAY FRANKLIN R               0.0        -201641.0                  0.0   \n",
       "\n",
       "                                 email_address from_poi_to_this_person  \n",
       "ALLEN PHILLIP K        phillip.allen@enron.com                    47.0  \n",
       "BADUM JAMES P                              NaN                     NaN  \n",
       "BANNANTINE JAMES M  james.bannantine@enron.com                    39.0  \n",
       "BAXTER JOHN C                              NaN                     NaN  \n",
       "BAY FRANKLIN R             frank.bay@enron.com                     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see NaN values have been replaced.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll examine the financial features to see if there are any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<seaborn.axisgrid.FacetGrid at 0x1113a7ed0>"
||||||| merged common ancestors
       "<seaborn.axisgrid.FacetGrid at 0x10de65490>"
=======
       "<seaborn.axisgrid.FacetGrid at 0x1a09eac790>"
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHsCAYAAAA0BWxRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
<<<<<<< HEAD
       "<matplotlib.figure.Figure at 0x1113a77d0>"
||||||| merged common ancestors
       "<matplotlib.figure.Figure at 0x10de65e50>"
=======
       "<matplotlib.figure.Figure at 0x1a09eac690>"
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot('total_payments', 'bonus', \n",
    "           data=df, \n",
    "           fit_reg=False, \n",
    "           hue='poi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an obvious outlier in the plot above. After comparing the data point to the salary documents it turns out that this point is the 'TOTAL' value of all the listed salries. Since this doesn't represent anyone in particular it will be manually removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['TOTAL'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9e8fca0e890c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TOTAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sns.lmplot('total_payments', 'total_stock_value', \n\u001b[1;32m      4\u001b[0m            \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mfit_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sian/anaconda/envs/DAND/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   1905\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1908\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sian/anaconda/envs/DAND/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3262\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3263\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['TOTAL'] not contained in axis"
     ]
    }
   ],
   "source": [
    "df = df.drop('TOTAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing this point it looks like there are still some outliers. These other outliers are people with extremely high salaries/bonuses. Even though they look like outliers they are in fact accurate values, many of which correspond to POIs, so they won't be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating new features\n",
    "\n",
    "Two new features will be created: (i) fracion_msgs_to_poi and (ii) fracion_msgs_from_poi. These are the fractions of messages a person sends/receives to/from a POI. These two features are helpful as they measure the proportion of emails that are related to a POI. Someone who sends/receives a lot of emails to/from a POI is more likely to be a POI themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "df_new['fracion_msgs_to_poi'] = df.from_this_person_to_poi / df.from_messages\n",
    "df_new['fracion_msgs_from_poi'] = df.from_poi_to_this_person / df.to_messages"
   ]
  },
  {
<<<<<<< HEAD
||||||| merged common ancestors
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the data set in to a training and testing set. Using StratifiedShuffleSplit returns stratified randomized folds. Since the data set we are dealing with is relatively small and unbalanced using StratifiedShuffleSplit to randomly split the dataset, and use the whole dataset for both buidling and assessing the model should lead to a more stable evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['poi', 'email_address'], axis=1)\n",
    "X = data.values\n",
    "y = df.poi"
   ]
  },
  {
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN:', array([ 65,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "        86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "       112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 140, 141, 142, 143, 144]), 'TEST:', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68,\n",
      "       69, 70, 71, 72, 73]))\n",
      "('TRAIN:', array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68,\n",
      "       69, 70, 71, 72, 73]), 'TEST:', array([ 65,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "        86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "       112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 140, 141, 142, 143, 144]))\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "## Testing various ML methods on the dataset"
||||||| merged common ancestors
    "## Classifying the dataset"
=======
    "# Generate the training and testing data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 25,
||||||| merged common ancestors
   "cell_type": "code",
   "execution_count": 12,
=======
   "cell_type": "markdown",
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Prepare features and labels for machine learning\n",
||||||| merged common ancestors
    "# Now let's split our data into features and labels, as well as training and testing sets.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = df.drop(['poi', 'email_address'], axis=1)\n",
    "y = df.poi\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca10 = pca.transform(X_train)\n",
    "X_test_pca10 = pca.transform(X_test)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca3 = pca.transform(X_train)\n",
    "X_test_pca3 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sian/anaconda/envs/DAND/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:108: RuntimeWarning: invalid value encountered in divide\n",
      "  msb = ssbn / float(dfbn)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
=======
    "## Feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of feature reduction is to select the best number of top features or reduce dimension of features.\n",
    "\n",
    "PCA (Principal Component Analysis) uses linear algebra to transform the dataset into a compressed form. I will start off by chosing 2-3 dimensions for PCA.\n",
    "\n",
    "SelectPercentile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca2 = pca.transform(X_train)\n",
    "X_test_pca2 = pca.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca5 = pca.transform(X_train)\n",
    "X_test_pca5 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
    "\n",
<<<<<<< HEAD
    "features = df.drop(['poi', 'email_address'], axis=1)\n",
    "labels = df.poi"
||||||| merged common ancestors
    "X_train_reduce50 = SelectPercentile(percentile=50).fit_transform(X_train, y_train)\n",
    "X_test_reduce50 = SelectPercentile(percentile=50).fit_transform(X_test, y_test)\n",
    "\n",
    "X_train_reduce10 = SelectPercentile().fit_transform(X_train, y_train)\n",
    "X_test_reduce10 = SelectPercentile().fit_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing accuracy of various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeanAccuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (10% of features)</th>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (50% of features)</th>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (PCA: 10 components)</th>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (PCA: 3 components)</th>\n",
       "      <td>0.838266</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.784708</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (10% of features)</th>\n",
       "      <td>0.784708</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (50% of features)</th>\n",
       "      <td>0.784708</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (PCA: 10 components)</th>\n",
       "      <td>0.792283</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (PCA: 3 components)</th>\n",
       "      <td>0.777308</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.644116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (10% of features)</th>\n",
       "      <td>0.644116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (50% of features)</th>\n",
       "      <td>0.644116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (PCA: 10 components)</th>\n",
       "      <td>0.644116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (PCA: 3 components)</th>\n",
       "      <td>0.644116</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.822763</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (10% of features)</th>\n",
       "      <td>0.846018</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (50% of features)</th>\n",
       "      <td>0.830514</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (PCA: 10 components)</th>\n",
       "      <td>0.830691</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (PCA: 3 components)</th>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MeanAccuracy  Precision  \\\n",
       "AdaBoost Classifier                                0.838266   0.222222   \n",
       "AdaBoost Classifier (10% of features)              0.838266   0.222222   \n",
       "AdaBoost Classifier (50% of features)              0.838266   0.222222   \n",
       "AdaBoost Classifier (PCA: 10 components)           0.838266   0.222222   \n",
       "AdaBoost Classifier (PCA: 3 components)            0.838266   0.222222   \n",
       "Decision Tree Classifier                           0.784708   0.444444   \n",
       "Decision Tree Classifier (10% of features)         0.784708   0.277778   \n",
       "Decision Tree Classifier (50% of features)         0.784708   0.388889   \n",
       "Decision Tree Classifier (PCA: 10 components)      0.792283   0.388889   \n",
       "Decision Tree Classifier (PCA: 3 components)       0.777308   0.388889   \n",
       "Gaussian Naive Bayes                               0.644116   0.444444   \n",
       "Gaussian Naive Bayes (10% of features)             0.644116   0.444444   \n",
       "Gaussian Naive Bayes (50% of features)             0.644116   0.444444   \n",
       "Gaussian Naive Bayes (PCA: 10 components)          0.644116   0.444444   \n",
       "Gaussian Naive Bayes (PCA: 3 components)           0.644116   0.444444   \n",
       "Random Forest Classifier                           0.822763   0.111111   \n",
       "Random Forest Classifier (10% of features)         0.846018   0.055556   \n",
       "Random Forest Classifier (50% of features)         0.830514   0.111111   \n",
       "Random Forest Classifier (PCA: 10 components)      0.830691   0.166667   \n",
       "Random Forest Classifier (PCA: 3 components)       0.853946   0.444444   \n",
       "\n",
       "                                                 Recall   F1Score  \n",
       "AdaBoost Classifier                            0.222222  0.222222  \n",
       "AdaBoost Classifier (10% of features)          0.222222  0.222222  \n",
       "AdaBoost Classifier (50% of features)          0.222222  0.222222  \n",
       "AdaBoost Classifier (PCA: 10 components)       0.222222  0.222222  \n",
       "AdaBoost Classifier (PCA: 3 components)        0.222222  0.222222  \n",
       "Decision Tree Classifier                       0.388889  0.388889  \n",
       "Decision Tree Classifier (10% of features)     0.333333  0.333333  \n",
       "Decision Tree Classifier (50% of features)     0.388889  0.333333  \n",
       "Decision Tree Classifier (PCA: 10 components)  0.277778  0.333333  \n",
       "Decision Tree Classifier (PCA: 3 components)   0.277778  0.444444  \n",
       "Gaussian Naive Bayes                           0.444444  0.444444  \n",
       "Gaussian Naive Bayes (10% of features)         0.444444  0.444444  \n",
       "Gaussian Naive Bayes (50% of features)         0.444444  0.444444  \n",
       "Gaussian Naive Bayes (PCA: 10 components)      0.444444  0.444444  \n",
       "Gaussian Naive Bayes (PCA: 3 components)       0.444444  0.444444  \n",
       "Random Forest Classifier                       0.000000  0.166667  \n",
       "Random Forest Classifier (10% of features)     0.166667  0.055556  \n",
       "Random Forest Classifier (50% of features)     0.166667  0.166667  \n",
       "Random Forest Classifier (PCA: 10 components)  0.111111  0.111111  \n",
       "Random Forest Classifier (PCA: 3 components)   0.055556  0.222222  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "models = {\"AdaBoost Classifier\": AdaBoostClassifier(), \"Gaussian Naive Bayes\": GaussianNB(), \n",
    "          \"Decision Tree Classifier\": tree.DecisionTreeClassifier(), \"Random Forest Classifier\": RandomForestClassifier()} \n",
    "          \n",
    "\n",
    "data = {\"\": X_train, \"(50% of features)\": X_train_reduce50, \"(10% of features)\": X_train_reduce10,\n",
    "       \"(PCA: 10 components)\": X_train_pca10, \"(PCA: 3 components)\": X_train_pca3}\n",
    "\n",
    "res = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        for scale, X in data.items():\n",
    "            n = name + \" \" + scale\n",
    "            clf = model\n",
    "            accuracy = cross_val_score(clf, X_train, y_train).mean()\n",
    "    \n",
    "            y_pred = cross_val_predict(clf, X_train, y_train)\n",
    "\n",
    "            rec = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "            prec = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "            f1 = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "\n",
    "\n",
    "            res[n] = {\"MeanAccuracy\": accuracy, \"Precision\": prec, \"Recall\": rec, \"F1Score\": f1}\n",
    "\n",
    "results = pd.DataFrame.from_dict(res, orient=\"index\")\n",
    "results = results[[\"MeanAccuracy\", \"Precision\", \"Recall\", \"F1Score\"]]\n",
    "\n",
    "results"
=======
    "X_train_reduce30 = SelectPercentile(percentile=30).fit_transform(X_train, y_train)\n",
    "X_test_reduce30 = SelectPercentile(percentile=30).fit_transform(X_test, y_test)\n",
    "\n",
    "X_train_reduce10 = SelectPercentile().fit_transform(X_train, y_train)\n",
    "X_test_reduce10 = SelectPercentile().fit_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing accuracy of various classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four algorithms will be tested: AdaBoost, Naive Bayes, Decision tree classifier and Random Forest. For each algorithm, evaluation metrics including accuracy, precision, recall and f1 score will be calculated for a varying number of features from SelectKBest and PCA methods. \n",
    "\n",
    "Accuracy, precision, recall and f1 score are used as metrics to evaluate the model performance. \n",
    "* Accuracy: True Positive + True Negative / (True Positive + True Negative + False Positive + False Negative). Accuracy measures the percentage of correctly identified POIs and non-POIs from all of the predictions made. Accuracy is a good initial indicator but it can be misleading.\n",
    "* Precision: True Positive / (True Positive + False Positive). Precision measures how many of the items labeled as positive truely belong to the positive class.\n",
    "* Recall:  True Positive / (True Positive + False Negative). Recall measure out of all the items that are truely positive, how many were correctly classified as positive. \n",
    "* F1 score gives a harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeanAccuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (10% of features)</th>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (30% of features)</th>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (PCA: 2 components)</th>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier (PCA: 5 components)</th>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (10% of features)</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (30% of features)</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (PCA: 2 components)</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (PCA: 5 components)</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (10% of features)</th>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (30% of features)</th>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (PCA: 2 components)</th>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes (PCA: 5 components)</th>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (10% of features)</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (30% of features)</th>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (PCA: 2 components)</th>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier (PCA: 5 components)</th>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              MeanAccuracy  Precision  \\\n",
       "AdaBoost Classifier                               0.779444   0.222222   \n",
       "AdaBoost Classifier (10% of features)             0.779444   0.222222   \n",
       "AdaBoost Classifier (30% of features)             0.779444   0.222222   \n",
       "AdaBoost Classifier (PCA: 2 components)           0.779444   0.222222   \n",
       "AdaBoost Classifier (PCA: 5 components)           0.779444   0.222222   \n",
       "Decision Tree Classifier                          0.835000   0.666667   \n",
       "Decision Tree Classifier (10% of features)        0.835000   0.666667   \n",
       "Decision Tree Classifier (30% of features)        0.835000   0.666667   \n",
       "Decision Tree Classifier (PCA: 2 components)      0.835000   0.666667   \n",
       "Decision Tree Classifier (PCA: 5 components)      0.835000   0.666667   \n",
       "Gaussian Naive Bayes                              0.421667   0.777778   \n",
       "Gaussian Naive Bayes (10% of features)            0.421667   0.777778   \n",
       "Gaussian Naive Bayes (30% of features)            0.421667   0.777778   \n",
       "Gaussian Naive Bayes (PCA: 2 components)          0.421667   0.777778   \n",
       "Gaussian Naive Bayes (PCA: 5 components)          0.421667   0.777778   \n",
       "Random Forest Classifier                          0.876667   0.000000   \n",
       "Random Forest Classifier (10% of features)        0.835000   0.111111   \n",
       "Random Forest Classifier (30% of features)        0.862222   0.333333   \n",
       "Random Forest Classifier (PCA: 2 components)      0.848889   0.000000   \n",
       "Random Forest Classifier (PCA: 5 components)      0.848889   0.000000   \n",
       "\n",
       "                                                Recall   F1Score  \n",
       "AdaBoost Classifier                           0.222222  0.222222  \n",
       "AdaBoost Classifier (10% of features)         0.222222  0.222222  \n",
       "AdaBoost Classifier (30% of features)         0.222222  0.222222  \n",
       "AdaBoost Classifier (PCA: 2 components)       0.222222  0.222222  \n",
       "AdaBoost Classifier (PCA: 5 components)       0.222222  0.222222  \n",
       "Decision Tree Classifier                      0.555556  0.666667  \n",
       "Decision Tree Classifier (10% of features)    0.444444  0.666667  \n",
       "Decision Tree Classifier (30% of features)    0.666667  0.444444  \n",
       "Decision Tree Classifier (PCA: 2 components)  0.444444  0.444444  \n",
       "Decision Tree Classifier (PCA: 5 components)  0.444444  0.444444  \n",
       "Gaussian Naive Bayes                          0.777778  0.777778  \n",
       "Gaussian Naive Bayes (10% of features)        0.777778  0.777778  \n",
       "Gaussian Naive Bayes (30% of features)        0.777778  0.777778  \n",
       "Gaussian Naive Bayes (PCA: 2 components)      0.777778  0.777778  \n",
       "Gaussian Naive Bayes (PCA: 5 components)      0.777778  0.777778  \n",
       "Random Forest Classifier                      0.000000  0.111111  \n",
       "Random Forest Classifier (10% of features)    0.111111  0.111111  \n",
       "Random Forest Classifier (30% of features)    0.222222  0.111111  \n",
       "Random Forest Classifier (PCA: 2 components)  0.000000  0.111111  \n",
       "Random Forest Classifier (PCA: 5 components)  0.000000  0.222222  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "models = {\"AdaBoost Classifier\": AdaBoostClassifier(), \"Gaussian Naive Bayes\": GaussianNB(), \n",
    "          \"Decision Tree Classifier\": tree.DecisionTreeClassifier(), \"Random Forest Classifier\": RandomForestClassifier()} \n",
    "          \n",
    "\n",
    "data = {\"\": X_train, \"(30% of features)\": X_train_reduce30, \"(10% of features)\": X_train_reduce10,\n",
    "       \"(PCA: 2 components)\": X_train_pca2, \"(PCA: 5 components)\": X_train_pca5}\n",
    "\n",
    "res = {}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        for scale, X in data.items():\n",
    "            n = name + \" \" + scale\n",
    "            clf = model\n",
    "            accuracy = cross_val_score(clf, X_train, y_train).mean()\n",
    "    \n",
    "            y_pred = cross_val_predict(clf, X_train, y_train)\n",
    "\n",
    "            rec = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "            prec = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "            f1 = cross_val_score(clf, X_train, y_train, scoring=make_scorer(recall_score)).mean()\n",
    "\n",
    "\n",
    "            res[n] = {\"MeanAccuracy\": accuracy, \"Precision\": prec, \"Recall\": rec, \"F1Score\": f1}\n",
    "\n",
    "results = pd.DataFrame.from_dict(res, orient=\"index\")\n",
    "results = results[[\"MeanAccuracy\", \"Precision\", \"Recall\", \"F1Score\"]]\n",
    "\n",
    "results"
>>>>>>> 34b1c991ea75634be4fafb9f58067955c2d167e9
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note on accuracy: as shown above, accuracy can be a misleading metric. Take a look at the Random Forest Classifier ithout any parameter tuning. It has a relatively high accuracy score of 0.876, but it scored a 0 in both precision and recall! This model is doing nothing but reflecting the distribution of our underlying classes. If we hadn't taken precision and recall into account, we could have missed that. I think that the unbalanced classes could be contributing to the underwhelming initial performance, so parameter tuning will take on an added performance here.\n",
    "\n",
    "Our best performing classifier in terms of recall was the Gaussian Naive Bayes classifier. With a recall of 77%, this classifier correctly flagged more than half of the POIs in our data. That classifier also had the highest F1 score (the harmonic mean of precision and recall).\n",
    "\n",
    "Now let's do some parameter tuning, in the hopes that some penalty and class weight parameters might be able to bring up the recall of some other models in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** What does it mean to tune the parameters of an algorithm, and what can happen if you donâ€™t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? *****\n",
    "\n",
    "Parameter tuning searches for optimized parameters for a given algorithm. It is an important step because even if a well suited algorithm is used without the correct paarmeters it can perform poorly. In order to acheive the best possible results we can use GridSerchCV to search for the best parameters to use for a given algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sian/anaconda/envs/DAND/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'class_weight': {0: 2, 1: 1}, 'min_samples_split': 20}, 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "default_recall = make_scorer(recall_score, pos_label=0)\n",
    "\n",
    "param_grid = {\"class_weight\": [\"balanced\", {0: 2, 1: 1}, {0: 5, 1: 1}, {0: 10, 1: 1}], \n",
    "              \"min_samples_split\": [2, 3, 5, 10, 20]}\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "clf = GridSearchCV(forest, param_grid=param_grid, scoring=default_recall)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_params_, clf.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is validation, and whatâ€™s a classic mistake you can make if you do it wrong? How did you validate your analysis? \n",
    "\n",
    "Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithmâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "\n",
    "**4. What does it mean to tune the parameters of an algorithm, and what can happen if you donâ€™t do this well?**  \n",
    "\n",
    "**How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).**  \n",
    "\n",
    "\n",
    "**5. What is validation, and whatâ€™s a classic mistake you can make if you do it wrong? How did you validate your analysis?**\n",
    "\n",
    "**6. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithmâ€™s performance. **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files included in this project:\n",
    "* **poi_id.py :** Code for the POI identifier.\n",
    "* **final_project_dataset.pkl :** The dataset for the project. \n",
    "* **tester.py :** Used to test the functionality of the poi_id.py file. \n",
    "* **emails_by_address :** This directory contains many text files, each of which contains all the messages to or from a particular email address. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
